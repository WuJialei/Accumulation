# 关于ZooKeeper的学习总结

**1 分布式相关理论**

--1.1 事务(本地事务处理或者集中式事务处理)

- 事务概念：对数据库中一系列操作进行统一的回滚或者提交的操作，主要用来保证数据的完整性和一致性

- 事务四大特性(ACID)
   - 原子性（Atomicity）:原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚。因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响
   - 一致性（Consistency）:事务是从一个一致性状态转移到另一个一致性的状态。事务开始前和结束后，数据库的完整性约束没有被破坏。比如A向B转账，不可能A扣了钱，B却没收到
   - 隔离性（Isolation）:隔离性是当多个用户并发访问数据库时，多个并发事务之间要相互隔离。同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账
   - 持久性（Durability）:持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的。即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作

- 事务的隔离级别
   - 读未提交：另一个事务修改了数据，但尚未提交，而本事务中的SELECT会读到这些未被提交的数据脏读
   - 读提交：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果因此本事务先后两次读到的数据结果会不一致
   - 可重复读：在同一个事务里，SELECT的结果是事务开始时时间点的状态，因此，同样的SELECT操作读到的结果会是一致的。但是，会有幻读现象
   - 串行化：最高的隔离级别，在这个隔离级别下，不会产生任何异常。并发的事务，就像事务是在一个个按照顺序执行一样

- 事务的并发问题
   - 脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据
   - 不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果因此本事务先后两次读到的数据结果会不一致
   - 幻读：可重复读隔离级别解决了不可重复读问题，保证了同一个事务里，查询的结果都是事务开始时的状态（一致性）。事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作 这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。 而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有跟没有修改一样，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读
   - 幻读与不可重复读区别：不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表

- 事务隔离级别与事务并发问题关系
    |事务隔离级别|脏读|不可重复读|幻读|
    |--|--|--|--|
    |读为提交|是|是|是|
    |读提交|否|是|是|
    |可重复读|否|否|是|
    |串行化|否|否|否|

- MySQL默认的事务隔离级别为repeatable-read可重复读，事务的隔离级别要得到底层数据库引擎的支持。未提交读时，写数据只会锁住相应的行；可重复读时，写数据会锁住整张表；串行化时，读写数据都会锁住整张表。隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大，鱼和熊掌不可兼得啊。对于多数应用程序，可以优先考虑把数据库系统的隔离级别设为Read Committed，它能够避免脏读取，而且具有较好的并发性能。尽管它会导致不可重复读、幻读这些并发问题，在可能出现这类问题的个别场合，可以由应用程序采用悲观锁或乐观锁来控制。

--1.2 分布式事务

- 事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于分布式系统的不同节点之上

- 分布式事务是指会涉及到操作多个数据库的事务。其实就是将对同一库事务的概念扩大到了对多个库的事务。目的是为了保证分布式系统中的数据一致性。分布式事务处理的关键是必须有一种方法可以知道事务在任何地方所做的所有动作，提交或回滚事务的决定必须产生统一的结果（全部提交或全部回滚）

- 分布式系统经典理论
   - CAP
   - BASE

- CAP
   - CAP理论：一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项
   - Consistency 一致性，一致性指“all nodes see the same data at the same time”，说的就是数据一致性。即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致。以下有三种一致性策略
      - 强一致性：要求更新过的数据能被后续的访问都能看到
      - 弱一致性：能容忍后续的部分或者全部访问不到
      - 最终一致性：经过一段时间后要求能访问到更新后的数据
      - CAP中说，不可能同时满足的这个一致性指的是强一致性
   - Availability 可用性，可用性指“Reads and writes always succeed”，即在正常响应时间服务一直可用
   - Partition Tolerance分区容错性，分区容错性指“the system continues to operate despite arbitrary message loss or failure of part of the system”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务
   - 在CAP理论中。C，A，P三者并不是平等的，对于一个分布式系统来说。P是一个基本要求，CAP三者中，只能在CA两者之间做权衡，并且要想尽办法提升P
   - CP without A，如果一个分布式系统不要求强的可用性，即容许系统停机或者长时间无响应的话，就可以在CAP三者中保障CP而舍弃A。一个保证了CP而一个舍弃了A的分布式系统，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。设计成CP的系统其实也不少，其中最典型的就是很多分布式数据库，在发生极端情况时，优先保证数据的强一致性，代价就是舍弃系统的可用性。如Redis、HBase等，还有分布式系统中常用的Zookeeper也是在CAP三者之中选择优先保证CP的
   - AP without C，要高可用并允许分区，则需放弃一致性。一旦网络问题发生，节点之间可能会失去联系。为了保证高可用，需要在用户访问时可以马上得到返回，则每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。这种舍弃强一致性而保证系统的分区容错性和可用性的场景和案例非常多。前面我们介绍可用性的时候说到过，很多系统在可用性方面会做很多事情来保证系统的全年可用性可以达到N个9，所以，对于很多业务系统来说，比如淘宝的购物，12306的买票。都是在可用性和一致性之间舍弃了一致性而选择可用性
   
- BASE
   - BASE是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）
   - 基本可用（Basically Available）：基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用
   - 软状态（ Soft State）：软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性
   - 最终一致性（ Eventual Consistency）：最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态
   - ACID和BASE的区别与联系：ACID是传统数据库常用的设计理念，追求强一致性模型。BASE支持的是大型分布式系统，提出通过牺牲强一致性获得高可用性。ACID和BASE代表了两种截然相反的设计哲学。在分布式系统设计的场景中，系统组件对一致性要求是不同的，因此ACID和BASE又会结合使用

--1.3 分布式一致性的协议和算法

- 协议和算法
   - 2PC：二阶提交协议（Two Phase Commitment Protocol）
   - 3PC：三阶提交协议（Three Phase Commitment Protocol）
   - Paxos：帕克索斯算法

- 2PC
   - 两个阶段是指：第一阶段：准备阶段(投票阶段)和第二阶段：提交阶段（执行阶段）。
   - 准备阶段：事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种“万事俱备，只欠东风”的状态
   - 提交阶段：如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源
   - 缺点：协调者单点故障问题，协调者发生故障。参与者会一直阻塞下去；在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作；协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据不一致性的现象

- 3PC
   - 3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段
   - CanCommit阶段：3PC的CanCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应
   - PreCommit阶段：协调者根据参与者的反应情况来决定是否可以记性事务的PreCommit操作。根据响应情况，有以下两种可能。假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的预执行；假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断
   - doCommit阶段：该阶段进行真正的事务提交，在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。（其实这个应该是基于概率来决定的，当进入第三阶段时，说明参与者在第二阶段已经收到了PreCommit请求，那么协调者产生PreCommit请求的前提条件是他在第二阶段开始之前，收到所有参与者的CanCommit响应都是Yes。（一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了）所以，一句话概括就是，当进入第三阶段时，由于网络超时等原因，虽然参与者没有收到commit或者abort响应，但是他有理由相信：成功提交的几率很大。 ）
   - 2PC与3PC的区别：相对于2PC，3PC主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况

- Paxos
   - Lamport虚拟了一个叫做Paxos的希腊城邦，这个岛按照议会民主制的政治模式制订法律，将议员的角色分为 proposers，acceptors，和 learners（允许身兼数职）
      - proposers 提出提案，提案信息包括提案编号和提议的 value
      - acceptor 收到提案后可以接受（accept）提案，若提案获得多数派（majority）的 acceptors 的接受，则称该提案被批准（chosen）
      - learners 只能“学习”被批准的提案
   - 决议的提出与批准：一个决议分为两个阶段
      - prepare阶段
         - proposer选择一个提案编号n并将prepare请求发送给acceptors中的一个多数派
         - acceptor收到prepare消息后，如果提案的编号大于它已经回复的所有prepare消息(回复消息表示接受accept)，则acceptor将自己上次接受的提案回复给proposer，并承诺不再回复小于n的提案
      - 批准阶段
         - 当一个proposer收到了多数acceptors对prepare的回复后，就进入批准阶段。它要向回复prepare请求的acceptors发送accept请求，包括编号n和根据P2c决定的value
         - 在不违背自己向其他proposer的承诺的前提下，acceptor收到accept请求后即批准这个请求
   - 决议的发布：当acceptors批准一个value时，将这个消息发送给所有learners。但是这个方法会导致消息量过大。因此acceptors需要将accept消息发送给learners的一个子集，然后由这些learners去通知所有learners。

--1.4 本部分参考

- [史上最全的数据库面试题，不看绝对后悔](https://www.nowcoder.com/discuss/135748)
- [学习分布式不得不会的ACP理论](https://mp.weixin.qq.com/s/DUOsYUTuKM6mhahqiaWXCA)
- [分布式系统的BASE理论](http://www.hollischuang.com/archives/672)
- [关于分布式事务、两阶段提交协议、三阶提交协议](http://www.hollischuang.com/archives/681)
- [Paxos算法](https://zh.wikipedia.org/wiki/Paxos%E7%AE%97%E6%B3%95)

**2 ZooKeeper**

--2.1 ZooKeeper概念

- 一个分布式数据一致性的解决方案，一个开放源代码的分布式协调服务

- 以基于 ZooKeeper 实现诸如数据发布/订阅、分布式锁、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举和分布式队列等功能

- ZooKeeper 集群最好使用奇数台服务器(2N + 1，N > 0)构成。在Zookeeper中 Leader 选举算法采用了Zab协议。Zab核心思想是当多数 Server 写成功，则任务数据写成功。①如果有3个Server，则最多允许1个Server 挂掉。②如果有4个Server，则同样最多允许1个Server挂掉。既然3个或者4个Server，同样最多允许1个Server挂掉，那么它们的可靠性是一样的，所以选择奇数个ZooKeeper Server即可，这里选择3个Server

- 高可用：以集群形态来部署 ZooKeeper，只要半数以上节点存活，ZooKeeper 就能正常服务.这样只要集群中大部分机器是可用的（能够容忍一定的机器故障），那么 ZooKeeper 本身仍然是可用的

- 高吞吐量和低延迟：ZooKeeper  将数据保存在内存中，每个节点的存储数据上限为1M

- 高性能：在“读”多于“写”的应用程序中尤其地高性能，因为“写”会导致所有的服务器间同步状态

- ZooKeeper可以保证如下分布式一致性特性
   - 顺序一致性：从同一个客户端发起的事务请求，最终将会严格地按照其发起顺序被应用到Zookeeper中
   - 原子性：所有事务的请求结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么在整个集群中所有机器上都成功应用了某一个事务，要么都没有应用，没有中间状态
   - 单一视图：无论客户端连接的是哪个Zookeeper服务器，其看到的服务端数据模型都是一致的
   - 可靠性：一旦服务端成功应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会被一直保留下来，除非有另一个事务又对其进行了变更
   - 实时性：Zookeeper仅仅保证在一定的时间内，客户端最终一定能够从服务端上读到最终的数据状态

--2.2 系统模型

- Zookeeper的数据节点称为ZNode，ZNode是Zookeeper中数据的最小单元，每个ZNode都可以保存数据，同时还可以挂载子节点，因此构成了一个层次化的命名空间，称为树

- Zookeeper中，事务是指能够改变Zookeeper服务器状态的操作，一般包括节点创建与删除\数据节点内容更新和客户端会话创建与失效.对于每个事务请求，Zookeeper都会为其分配一个全局唯一的事务ID，用ZXID表示，通常是64位的数字，每个ZXID对应一次更新操作，从这些ZXID中可以间接地识别出Zookeeper处理这些更新操作请求的全局顺序
   - 在 ZAB (ZooKeeper Atomic Broadcast , ZooKeeper 原子消息广播协议) 协议的事务编号 Zxid设计 中， Zxid 是一个 64 位的数字(epoch[32] + id[32])，其中低 32 位是一个简单的单调递增的计数器，针对客户端每一个事务请求，计数器加 1;而高 32 位则代表 Leader 周期 epoch 的编号，每个当选产生一个新的 Leader 服务器，就会从这个 Leader 服务器上取出其本地日志中最大事务的 ZXID，并从中读取epoch 值，然后加 1，以此作为新的 epoch，并将低 32 位从 0 开始计数
   - epoch:可以理解为当前集群所处的年代或者周期，每个 leader 就像皇帝，都有自己的年号，所以每次改朝换代， leader 变更之后，都会在前一个年代的基础上加1
   - 为了保证顺序性，该 zkid 必须单调递增

- Zookeeper中，每个数据节点都是由生命周期的，类型不同则会不同的生命周期，节点类型可以分为持久节点（PERSISTENT）、临时节点（EPHEMERAL）、顺序节点（SEQUENTIAL）三大类，可以通过组合生成如下四种类型节点
   - 持久节点（PERSISTENT）：节点创建后便一直存在于Zookeeper服务器上，直到有删除操作来主动清楚该节点
   - 持久顺序节点（PERSISTENT_SEQUENTIAL）：相比持久节点，其新增了顺序特性，每个父节点都会为它的第一级子节点维护一份顺序，用于记录每个子节点创建的先后顺序。在创建节点时，会自动添加一个数字后缀，作为新的节点名，该数字后缀的上限是整形的最大值
   - 临时节点（EPEMERAL）：临时节点的生命周期与客户端会话绑定，客户端失效，节点会被自动清理。同时，Zookeeper规定不能基于临时节点来创建子节点，即临时节点只能作为叶子节点
   - 临时顺序节点（EPEMERAL_SEQUENTIAL）：在临时节点的基础添加了顺序特性

- 版本
   - 保证分布式数据原子性操作
   - 每个数据节点都具有三种类型的版本信息，对数据节点的任何更新操作都会引起版本号的变化
      - version：当前数据节点数据内容的版本
      - cversion：当前数据子节点的版本号
      - aversion：当前数据节点ACL变更版本号
   - 各版本号都是表示修改次数，如version为1表示对数据节点的内容变更了一次。即使前后两次变更并没有改变数据内容，version的值仍然会改变。version可以用于写入验证，类似于CAS

- Watcher
   - 数据变更的通知
   - 一个Watch事件是一个一次性的触发器，当被设置了Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了Watch的客户端，以便通知它们
   - ZooKeeper机制的特点
      - 一次性的触发器（one-time trigger）：当数据改变的时候，那么一个Watch事件会产生并且被发送到客户端中。但是客户端只会收到一次这样的通知，如果以后这个数据再次发生改变的时候，之前设置Watch的客户端将不会再次收到改变的通知，因为Watch机制规定了它是一个一次性的触发器
      - 发送给客户端（Sent to the client）：Watch的通知事件是从服务器发送给客户端的，是异步的，这就表明不同的客户端收到的Watch的时间可能不同，但是ZooKeeper有保证：当一个客户端在看到Watch事件之前是不会看到结点数据的变化的。例如：A=3，此时在上面设置了一次Watch，如果A突然变成4了，那么客户端会先收到Watch事件的通知，然后才会看到A=4
      - 被设置Watch的数据（The data for which the watch was set）：意味着 znode 节点本身具有不同的改变方式。ZooKeeper 维护了两条监视链表：数据监视和子节点监视(data watches and child watches) 
   - 实现永久监听
      - 由于zookeeper是一次性监听，所以我们必须在wather的process方法里面再设置监听。一个方法如下：以下逻辑是实现的是生产者和消费者模型，消费者监听某一路径下面子节点的变化，当生产者有消息发送过来的时候，在该节点下面创建一个子节点，然后把消息放到该子节点里面，这会触发消费者的process方法被调用，然后消费者取到该节点下面的子节点(顺便设置一个再监听该节点的子节点)，然后取出子节点的内容，做处理，然后删除该子节点
      ~~~
        public void process(WatchedEvent event) {
            // TODO Auto-generated method stub
            if (event.getState() == KeeperState.SyncConnected) {
                System.out.println("watcher received event");
                countDownLatch.countDown();
            }
            System.out.println("回调watcher1实例： 路径" + event.getPath() + " 类型："+ event.getType());
            // 事件类型，状态，和检测的路径
            EventType eventType = event.getType();
            KeeperState state = event.getState();
            String watchPath = event.getPath();
            switch (eventType) {
                case NodeCreated:
                    break;
                case NodeDataChanged:
                    break;
                case NodeChildrenChanged:
                    try {
                        //处理收到的消息
                        handleMessage(watchPath);
                    } catch (UnsupportedEncodingException e) {
                        // TODO Auto-generated catch block
                        e.printStackTrace();
                    } catch (KeeperException e) {
                        // TODO Auto-generated catch block
                        e.printStackTrace();
                    } catch (InterruptedException e) {
                        // TODO Auto-generated catch block
                        e.printStackTrace();
                    }
                    break;
                default:
                    break;
            }
        }

        public void handleMessage(String watchPath) throws KeeperException,InterruptedException, UnsupportedEncodingException {
            System.out.println("收到消息");
            //再监听该子节点
            List<String> Children = this.getChildren(watchPath);
            for (String a : Children) {
                String childrenpath = watchPath + "/" + a;
                byte[] recivedata = this.getData(childrenpath);
                String recString = new String(recivedata, "UTF-8");
                System.out.println("receive the path:" + childrenpath + ":data:"+ recString);
                //做完了之后，删除该节点
                this.deletNode(childrenpath, -1);
            }
        }

        public List<String> getChildren(String path) throws KeeperException,InterruptedException {
            //监听该节点子节点的变化情况
            return this.zooKeeper.getChildren(path, this);
        }
        public Stat setData(String path, byte[] data, int version)throws KeeperException, InterruptedException {
            return this.zooKeeper.setData(path, data, version);
        }
      ~~~
   
- ACL机制(Access Control Lists)
   - 保障数据的安全
   - 对数据节点的权限控制
   - 定义了五种权限(crwda)
      - CREATE：创建子节点的权限
      - READ：获取节点数据和子节点列表的权限
      - WRITE：更新节点数据的权限
      - DELETE：删除子节点的权限
      - ADMIN：设置节点ACL的权限
   - 通常使用"scheme : id : permission"来标识一个有效的ACL信息，权限模式（Scheme）、授权对象（ID）、权限（Permission），有4种权限模式
      - IP，通过IP地址粒度来进行权限控制
      - Digest，使用"username:password"形式的权限标识来进行权限配置
      - World，最为开放的权限控制模式，数据节点的访问权限对所有用户开放
      - Super，超级用户，是一种特殊的Digest模式，超级用户可以对任意Zookeeper上的数据节点进行任何操作

--2.3 序列化和协议

- ZooKeeper的客户端与服务端之间会进行一系列的网络通信来实现数据传输，Zookeeper使用Jute组件来完成数据的序列化和反序列化操作

- Jute是Zookeeper底层序列化组件，其用于Zookeeper进行网络数据传输和本地磁盘数据存储的序列化和反序列化工作

- 基于TCP/IP协议，ZooKeeper实现了自己的通信协议来玩按成客户端与服务端、服务端与服务端之间的网络通信，对于请求，主要包含请求头和请求体，对于响应，主要包含响应头和响应体

--2.4 会话管理

- ZooKeeper的会话管理主要是通过SessionTracker来负责，其采用了分桶策略（将类似的会话放在同一区块中进行管理）进行管理，以便ZooKeeper对会话进行不同区块的隔离处理以及同一区块的统一处理

- Zookeeper将所有的会话都分配在不同的区块一种，分配的原则是每个会话的下次超时时间点（ExpirationTime）。ExpirationTime指该会话最近一次可能超时的时间点。同时，Zookeeper Leader服务器在运行过程中会定时地进行会话超时检查，时间间隔是ExpirationInterval，默认为tickTime的值，ExpirationTime的计算时间如下：
~~~
ExpirationTime = ((CurrentTime + SessionTimeOut) / ExpirationInterval + 1) * ExpirationInterval
~~~

- 为了保持客户端会话的有效性，客户端会在会话超时时间过期范围内向服务端发送PING请求来保持会话的有效性（心跳检测）。服务端需要不断地接收来自客户端的心跳检测，并且需要重新激活对应的客户端会话，这个重新激活过程称为TouchSession。会话检测流程如下：
   - 检查该会话是否已经被关闭。若已经被关闭，则直接返回即可
   - 计算该会话新的超时时间ExpirationTime_New。使用上面提到的公式计算下一次超时时间点
   - 获取该会话上次超时时间ExpirationTime_Old。计算该值是为了定位其所在的区块
   - 迁移会话。将该会话从老的区块中取出，放入ExpirationTime_New对应的新区块中

- 对于会话的超时检查而言，Zookeeper使用SessionTracker来负责，SessionTracker使用单独的线程（超时检查线程）专门进行会话超时检查，即逐个一次地对会话桶中剩下的会话进行清理。如果一个会话被激活，那么Zookeeper就会将其从上一个会话桶迁移到下一个会话桶中，如ExpirationTime 1 的session n 迁移到ExpirationTime n 中，此时ExpirationTime 1中留下的所有会话都是尚未被激活的，超时检查线程就定时检查这个会话桶中所有剩下的未被迁移的会话，超时检查线程只需要在这些指定时间点（ExpirationTime 1、ExpirationTime 2…）上进行检查即可，这样提高了检查的效率，性能也非常好

--2.5 ZAB协议

- ZAB（ZooKeeper Atomic Broadcast 原子广播） 协议是一种支持崩溃恢复的原子广播协议

- 所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为leader服务器，而余下的其他服务器则成为follower服务器。leader服务器负责将一个客户端事务请求转换成一个事务proposal，并将该proposal分发给集群中所有的follower服务器。之后leader服务器需要等待所有follower服务器的反馈，一旦超过半数的follower服务器进行了正确的反馈后，那么leader就会再次向所有的follower服务器分发commit消息，要求其将前一个proposal进行提交

- 基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。ZooKeeper设计成只允许唯一的一个Leader服务器来进行事务请求的处理。Leader服务器在接收到客户端的事务请求后，会生成对应的事务提案并发起一轮广播协议；而如果集群中的其他机器接收到客户端的事务请求，那么这些非Leader服务器会首先将这个事务请求转发给Leader服务器

- ZAB 协议两种基本的模式：崩溃恢复和消息广播
   - 崩溃恢复
      - 当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进人恢复模式并选举产生新的Leader服务器
      - 当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该Leader服务器完成了状态同步之后，ZAB协议就会退出恢复模式
      - 其中，所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和Leader服务器的数据状态保持一致
   - 消息广播
      - 当集群中已经有过半的Follower服务器完成了和Leader服务器的状态同步，那么整个服务框架就可以进人消息广播模式了。 当一台同样遵守ZAB协议的服务器启动后加人到集群中时，如果此时集群中已经存在一个Leader服务器在负责进行消息广播，那么新加人的服务器就会自觉地进人数据恢复模式：找到Leader所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去

- ZAB协议原理
   - ZAB主要包括消息广播和崩溃恢复两个过程，进一步可以分为三个阶段，分别是发现（Discovery）、同步（Synchronization）、广播（Broadcast）阶段
      - 发现，选举产生PL(prospective leader)，PL收集Follower epoch(cepoch)，根据Follower的反馈，PL产生newepoch(每次选举产生新Leader的同时产生新epoch)
      - 同步，PL补齐相比Follower多数派缺失的状态、之后各Follower再补齐相比PL缺失的状态，PL和Follower完成状态同步后PL变为正式Leader(established leader)
      - 广播，Leader处理客户端的写操作，并将状态变更广播至Follower，Follower多数派通过之后Leader发起将状态变更落地(deliver/commit)
   - ZAB的每一个分布式进程会循环执行这三个阶段，称为主进程周期。每个进程都有可能处于如下三种状态之一
      - LOOKING：Leader选举阶段
      - FOLLOWING：Follower服务器和Leader服务器保持同步状态
      - LEADING：Leader服务器作为主进程领导状态
   - 一个Follower只能和一个Leader保持同步，Leader进程和所有与所有的Follower进程之间都通过心跳检测机制来感知彼此的情况。若Leader能够在超时时间内正常收到心跳检测，那么Follower就会一直与该Leader保持连接，而如果在指定时间内Leader无法从过半的Follower进程那里接收到心跳检测，或者TCP连接断开，那么Leader会放弃当前周期的领导，转换到LOOKING状态

- ZAB与Paxos的联系和区别
   - 联系
      - 都存在一个类似于Leader进程的角色，由其负责协调多个Follower进程的运行
      - Leader进程都会等待超过半数的Follower做出正确的反馈后，才会将一个提议进行提交
      - 在ZAB协议中，每个Proposal中都包含了一个epoch值，用来代表当前的Leader周期，在Paxos算法中，同样存在这样的一个标识，名字为Ballot
   - 区别
      - Paxos算法中，新选举产生的主进程会进行两个阶段的工作，第一阶段称为读阶段，新的主进程和其他进程通信来收集主进程提出的提议，并将它们提交。第二阶段称为写阶段，当前主进程开始提出自己的提议
      - ZAB协议在Paxos基础上添加了同步阶段，此时，新的Leader会确保存在过半的Follower已经提交了之前的Leader周期中的所有事务Proposal
      - ZAB协议主要用于构建一个高可用的分布式数据主备系统，而Paxos算法则用于构建一个分布式的一致性状态机系统

--2.6 ZooKeeper集群中的角色

- 在 ZooKeeper 中没有选择传统的  Master/Slave 概念，而是引入了Leader、Follower 和 Observer 三种角色

- Leader
   - 既可以为客户端提供写服务又能提供读服务
   - 负责投票发起和决议

- Follower
   - 提供读服务
   - 参与 Leader 的选举过程
   - 参与写操作的“过半写成功”策略

- Observer 
   - 提供读服务，可以在不影响写性能的情况下提升集群的读性能

--2.7 Leader选举算法

- 服务器启动时期的Leader选举
   - 每个server会发出一个投票，由于是初始情况，因此对于server1和server2来说，都会将自己作为leader服务器来投票，每次投票包含的最基本的元素为：所推举的服务器的myid和zxid，我们以(myid, zxid)的形式来表示。因为是初始化阶段，因此无论是server1和是server2都会投给自己，即server1的投票为(1, 0)，server2的投票为(2, 0)，然后各自将这个投票发给集群中其它所有机器
   - 接收来自各个服务器的投票。每个服务器都会接收来自其它服务器的投票，接收到后会判断该投票的有效性，包括检查是否是本轮投票，是否来自looking状态的服务器
   - 处理投票。在接收到来自其它服务器的投票后，针对每一个投票，服务器都需要将别人的投票和自己的投票进行pk，pk的规则如下：优先检查zxid，zxid大的服务器优先作为leader。如果zxid相同，那么比较myid，myid大的服务器作为leader服务器
   - 统计投票。每次投票后，服务器都会统计所有投票，判断是否已经有过半的机器接收到相同的投票信息
   - 改变服务器状态。一旦确定了leader，每个服务器就会更新自己的状态，如果是follower，那么就变更为following，如果是leader，就变更为leading

- 服务器运行时期的Leader选举
   - 变更状态。当leader挂了之后，余下的非observer服务器都会将自己的状态变为looking，然后开始进行leader选举流程
   - 每个server会发出一个投票。在这个过程中，需要生成投票信息(myid, zxid)，因为是运行期间，因此每个服务器上的zxid可能不同，我们假定server1的zxid为123，而server3的zxid为122.在第一轮投票中，server1和server3都会投给自己，即分别产生投票(1, 123)和(3, 122)，然后各自将这个投票发给集群中的所有机器
   - 接收来自各个服务器的投票
   - 处理投票
   - 统计投票
   - 改变服务器状态

--2.8 数据同步

- 整个集群完成Leader选举后，Learner会向Leader进行注册，当Learner向Leader完成注册后，就进入数据同步环节，同步过程就是Leader将那些没有在Learner服务器上提交过的事务请求同步给Learner服务器

- peerLastZxid(该Learner最后处理的ZXID)、minCommittedLog(Leader提议缓存队列commitedLog中最小的ZXID)、maxCommittedLog(Leader提议缓存队列commitedLog中的最大ZXID)

- 集群数据同步通常分为四类
   - 直接差异化同步(DIFF同步，peerLastZxid介于minCommittedLog和maxCommittedLog之间)。Leader首先向这个Learner发送一个DIFF指令，用于通知Learner进入差异化数据同步阶段，Leader即将把一些Proposal同步给自己，针对每个Proposal，Leader都会通过发送PROPOSAL内容数据包和COMMIT指令数据包来完成
   - 先回滚再差异化同步(TRUNC+DIFF同步，Leader已经将事务记录到本地事务日志中，但是没有成功发起Proposal流程)。当Leader发现某个Learner包含了一条自己没有的事务记录，那么就需要该Learner进行事务回滚，回滚到Leader服务器上存在的，同时也是最接近于peerLastZxid的ZXID
   - 仅回滚同步(TRUNC同步，peerLastZxid大于maxCommittedLog)。Leader要求Learner回滚到ZXID值为maxCommittedLog对应的事务操作
   - 全量同步(SNAP同步，peerLastZxid小于minCommittedLog或peerLastZxid不等于lastProcessedZxid)。Leader无法直接使用提议缓存队列和Learner进行同步，因此只能进行全量同步。Leader将本机的全量内存数据同步给Learner。Leader首先向Learner发送一个SNAP指令，通知Learner即将进行全量同步，随后，Leader会从内存数据库中获取到全量的数据节点和会话超时时间记录器，将他们序列化后传输给Learner。Learner接收到该全量数据后，会对其反序列化后载入到内存数据库中

--2.9 ZooKeeper分布式锁的实现原理

- 如果有多个客户端A、B、C、D等N个客户端争抢一个zk分布式锁。大家都是上来直接创建一个锁节点下的一个接一个的临时顺序节点

- 如果自己不是第一个节点，就对自己上一个节点加监听器只要上一个节点释放锁，自己就排到前面去了，相当于是一个排队机制。而且用临时顺序节点的另外一个用意就是，如果某个客户端创建临时顺序节点之后，不小心自己宕机了也没关系，zk感知到那个客户端宕机，会自动删除对应的临时顺序节点，相当于自动释放锁，或者是自动取消自己的排队

--2.10 ZooKeeper开源客户端

- ZkClient

- Curator(基本使用参见[zookeeper_instance](https://github.com/WuJialei/zookeeper_instance))

--2.11 ZooKeeper在大型分布式系统中的使用

- kafka
   - [Kafka架构图](https://zhuanlan.zhihu.com/p/38269875)
   - [【分布式】Zookeeper在大型分布式系统中的应用](https://www.cnblogs.com/leesf456/p/6063694.html)

- [Zookeeper系列（6）-- Zookeeper的典型应用场景](https://blog.csdn.net/u013679744/article/details/79371022)


**3 参考**

- [《从Paxos到zookeeper分布式一致性原理与实践》笔记](https://blog.csdn.net/paincupid/article/details/78058087#commentBox)
- [可能是把 ZooKeeper 概念讲的最清楚的一篇文章](https://juejin.im/post/5b970f1c5188255c865e00e7#heading-18)
- [zookeeper之监听事件总结](https://blog.csdn.net/liu857279611/article/details/70495413)
- [从Paxos到zookeeper分布式一致性原理与实践]()
- [七张图彻底讲清楚ZooKeeper分布式锁的实现原理【石杉的架构笔记】](https://juejin.im/post/5c01532ef265da61362232ed#heading-0)
