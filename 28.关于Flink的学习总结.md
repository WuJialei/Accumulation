# 关于Flink的学习总结

**1 Flink的概念**

--1.1 基本概念

- 分布式

- 支持流处理和批处理

- 开源计算平台

--1.2 特点

- 统一的批处理和流处理系统

- Flink流处理的容错机制

- Flink流处理的时间窗口

**2 Flink的架构**

--2.1 基本架构

2.1.1 Flink包含了两种类型的处理器

- JobManager(Master)
   - 负责接收 flink 的作业，调度task，协调检查点，协调失败时恢复等
   - 收集 job 的状态、管理 TaskManagers
   - Flink运行时至少存在一个master处理器，如果配置高可用模式则会存在多个master处理器，它们其中有一个是leader，其他的都是standby

- TaskManager(Worker)
   - Flink中资源管理的基本组件，是所有执行任务的基本容器，提供了内存管理、IO管理、通信管理等一系列功能
   - MemoryManager Flink并没有把所有内存的管理都委托给JVM，因为JVM普遍存在着存储对象密度低、大内存时GC对系统影响大等问题。所以Flink自己抽象了一套内存管理机制，将所有对象序列化后放在自己的MemorySegment上进行管理
   - IOManager flink通过IOManager管理磁盘IO的过程，提供了同步和异步两种写模式，又进一步区分了block、buffer和bulk三种读写方式
   - NetworkEnvironment 是TaskManager的网络 IO 组件，包含了追踪中间结果和数据交换的数据结构。它的构造器会统一将配置的内存先分配出来，抽象成 NetworkBufferPool 统一管理内存的申请和释放
   - Flink运行时至少会存在一个worker处理器

2.1.2 Flink中计算资源的介绍

- TaskManager：Flink中资源管理的基本组件，是所有执行任务的基本容器
   - 每个TaskManager都是一个独立的JVM进程

- TaskManager可以分为一个或者多个Task Slot：每个Task Slot代表了TaskManager的一个固定大小的资源子集。例如，一个拥有3个slot的 TaskManager，会将其管理的内存平均分成三分分给各个slot。将资源slot化意味着来自不同job的task不会为了内存而竞争，而是每个task都拥有一定数量的内存储备。
   - 同一JVM(TaskManager)中的任务(Task Slot)共享TCP连接和心跳消息
   - TaskManager的一个Slot代表一个可用线程，该线程具有固定的内存，注意 Slot 只对内存隔离，没有对CPU隔离
   - 每个slot能运行一个或多个task(一个task是一个线程，task是执行计算的最小结构)
   - 每个TaskManager的Task Slot数目代表了该TaskManager的并发能力，任务的并发能力由所有TaskManager的Task Slot数目决定。有两个 Task Manager，每个 TaskManager有三个slot，这样我们的算子最大并行度那么就可以达到6个
   - slot 的数量通常与每个TaskManager的可用CPU内核数成比例。一般情况下你的slot数是每个TaskManager的cpu的核数
   - parallelism与slot的区别，参考[Flink--对parallelism 和 slot的理解](https://www.jianshu.com/p/b58988bcfb48)：slot是指taskmanager的并发执行能力；parallelism是指 taskmanager 实际使用的并发能力(并行度)，一个特定operator的subtask的个数被称之为其parallelism(并行度)；taskmanager.numberOfTaskSlots:3；即每一个 taskmanager 中的分配3个TaskSlot, 3个 taskmanager 一共有 9 个 TaskSlot。parallelism.default:1；即运行程序默认的并行度为 1，9 个 TaskSlot 只用了 1 个，有 8 个空闲。设置合适的并行度才能提高效率

- Task Slot允许多个task共享：每个Task Slot能运行一个或多个task，为了资源更充分的利用，Flink提出了SlotSharingGroup，尽可能地让多个task共享一个slot
   - 条件：它们都来自同一个Job的不同task的subtask(同一job的一个task下的相同subtask应该并行，不能放在同一个slot中)
   - slot共享有以下两点好处：1.Flink集群所需的task slots数与job中最高的并行度一致。也就是说我们不需要再去计算一个程序总共会起多少个task了；2.更容易获得更充分的资源利用。如果没有slot共享，那么非密集型操作source/flatmap就会占用同密集型操作 keyAggregation/sink 一样多的资源。如果有slot共享，将基线的2个并行度增加到6个，能充分利用slot资源，同时保证每个TaskManager能平均分配到重的subtasks(该部分看参考链接的图)

- 算子operators的Chaining：Flink提出了Chaining，尽可能地将operators chain在一起作为一个task来处理
   - Flink会尽可能地将operator的subtask链接（chain）在一起形成task。每个task在一个线程中执行。
   - 好处：将operators链接成task是非常有效的优化，它能减少线程之间的切换，减少消息的序列化/反序列化，减少数据在缓冲区的交换，减少了延迟的同时提高整体的吞吐量
   - 不是任意两个operator就能chain一起的，其条件还是很苛刻的(具体条件可看链接)
   - 出于分布式执行的目的，Flink将operator的subtask链接在一起形成task，每个task在一个线程中执行。将operators链接成task是非常有效的优化：它能减少线程之间的切换和基于缓存区的数据交换，在减少时延的同时提升吞吐量。链接的行为可以在编程API中进行指定


--2.2 运行架构

2.2.1 Flink的三种图结构(该部分主要参考[追源索骥：透过源码看懂Flink核心框架的执行流程之2.理解flink的图结构](https://www.cnblogs.com/bethunebtj/p/9168274.html#2%E7%90%86%E8%A7%A3flink%E7%9A%84%E5%9B%BE%E7%BB%93%E6%9E%84))

- StreamGraph
   - StreamGraph是对用户逻辑的映射
   - 代表程序的拓扑结构，是从用户代码直接生成的图
   - client执行env.execute()时生成

- JobGraph
   - JobGraph在StreamGraph基础上进行了一些优化，比如把一部分操作串成chain以提高效率
   - client生成
   - ExecutionGraph已经可以用于调度任务。我们可以看到，flink根据该图生成了一一对应的Task，每个task对应一个ExecutionGraph的一个Execution。Task用InputGate、InputChannel和ResultPartition对应了上面图中的IntermediateResult和ExecutionEdge

- ExecutionGraph
   - ExecutionGraph是为了调度存在的，加入了并行处理的概念
   - JobManager处生成，入口代码是ExecutionGraphBuilder.buildGraph（...）

2.2.2 Flink任务执行架构图

- 参考官网[Job Managers、Task Managers、客户端（Clients）](https://ci.apache.org/projects/flink/flink-docs-release-1.10/zh/concepts/runtime.html)

2.2.3 Flink任务的调度和执行

- Flink 集群启动后，首先会启动一个 JobManger 和多个的 TaskManager。用户的代码会由JobClient 提交给 JobManager，JobManager 再把来自不同用户的任务发给 不同的TaskManager 去执行，每个TaskManager管理着多个task，task是执行计算的最小结构， TaskManager 将心跳和统计信息汇报给 JobManager。TaskManager 之间以流的形式进行数据的传输。上述除了task外的三者均为独立的 JVM 进程。
- 要注意的是，TaskManager和job并非一一对应的关系。flink调度的最小单元是task而非TaskManager，也就是说，来自不同job的不同task可能运行于同一个TaskManager的不同线程上


--2.3 备注：该部分主要参考以下内容

- [Cris 带你快速入门 Flink之二 Flink基本架构](https://juejin.im/post/5c4f16dbe51d454f342fb7e7#heading-4)
- [追源索骥：透过源码看懂Flink核心框架的执行流程之3. 任务的调度与执行](https://www.cnblogs.com/bethunebtj/p/9168274.html#3-%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%B0%83%E5%BA%A6%E4%B8%8E%E6%89%A7%E8%A1%8C)
- [Flink 原理与实现：理解 Flink 中的计算资源](http://wuchong.me/blog/2016/05/09/flink-internals-understanding-execution-resources/)


**3 统一的批处理和流处理系统**

--3.1 流处理系统与批处理系统的不同

- 最大不同在于节点间的数据传输方式

- 流处理系统，节点间数据传输模型：当一条数据被处理完成后，序列化到缓存中，然后立刻通过网络传输到下一个节点，由下一个节点继续处理

- 批处理系统，其节点间数据传输模型是：当一条数据被处理完成后，序列化到缓存中，并不会立刻通过网络传输到下一个节点，当缓存写满，就持久化到本地硬盘上，当所有数据都被处理完成后，才开始将处理后的数据通过网络传输到下一个节点

- 流处理中，数据被一个节点处理完成后立即序列化化到缓存中传到下一个节点进行处理；而批处理在一个节点处理完后也会序列化到缓存中但会等到缓存写满并写入硬盘，所有数据处理完后才传到下一个节点

- 流处理对应低延迟的要求，批处理系统对应高吞吐量的要求

--3.2 Flink的执行引擎采用了一种十分灵活的方式，同时支持了上述两种数据传输模型

- 固定大小的缓存块 + 缓存块超时值

- Flink以固定的缓存块为单位进行网络数据传输，用户可以通过缓存块超时值指定缓存块的传输时机

- 缓存块的超时值为0，则Flink的数据传输方式类似上文所提到流处理系统的标准模型，此时系统可以获得最低的处理延迟

- 缓存块的超时值为无限大，则Flink的数据传输方式类似上文所提到批处理系统标准模型，此时系统可以获得最高的吞吐量

- 缓存块的超时值也可以设置为0到无限大之间的任意值。缓存块的超时阀值越小，则Flink流处理执行引擎的数据处理延迟越低，但吞吐量也会降低，反之亦然。通过调整缓存块的超时阀值，用户可根据需求灵活地权衡系统延迟和吞吐量

--3.3 备注：该部分主要参考[Flink 核心技术浅析（整理版）
](https://www.cnblogs.com/swordfall/p/10612404.html)

**4 Flink流处理的容错机制**

--4.1 Flink 提供的容错机制

- 分布式系统的容错：对于一个分布式系统来说，单个进程或是节点崩溃导致整个Job失败是经常发生的事情，在异常发生时不会丢失用户数据并能自动恢复才是分布式系统必须支持的特性之一

- 批处理系统的容错：由于文件可以重复访问，当个某个任务失败后，重启该任务即可

- Flink通过Checkpoint机制实现容错，该思想借鉴了Chandy和Lamport在1985年发表的一篇关于分布式快照的论文

--4.2 分布式快照Chandy Lamport算法逻辑(该部分主要参考[Flink 核心技术浅析（整理版）
之2.2 Flink流处理的容错机制](https://www.cnblogs.com/swordfall/p/10612404.html))

- 按照用户自定义的分布式快照间隔时间，Flink会定时在所有数据源中插入一种特殊的快照标记消息，这些快照标记消息和其他消息一样在DAG中流动，但是不会被用户定义的业务逻辑所处理，每一个快照标记消息都将其所在的数据流分成两部分：本次快照数据和下次快照数据

- 快照标记消息沿着DAG流经各个操作符，当操作符处理到快照标记消息时，会对自己的状态进行快照，并存储起来。当一个操作符有多个输入的时候，Flink会将先抵达的快照标记消息及其之后的消息缓存起来，当所有的输入中对应该快照的快照标记消息全部抵达后，操作符对自己的状态快照并存储，之后处理所有快照标记消息之后的已缓存消息。操作符对自己的状态快照并存储可以是异步与增量的操作，并不需要阻塞消息的处理

- 当所有的Data Sink（终点操作符）都收到快照标记信息并对自己的状态快照和存储后，整个分布式快照就完成了，同时通知数据源释放该快照标记消息之前的所有消息。若之后发生节点崩溃等异常情况时，只需要恢复之前存储的分布式快照状态，并从数据源重发该快照以后的消息就可以了

- 分布式快照的时间间隔越短，错误恢复的时间越少，与吞吐量负相关

--4.3 Flink Checkpoint机制具体实现流程(该部分主要参考：[追源索骥：透过源码看懂Flink核心框架的执行流程之5.1.4 Flink的分布式快照机制](https://www.cnblogs.com/bethunebtj/p/9168274.html#5-%E4%B8%BA%E6%89%A7%E8%A1%8C%E4%BF%9D%E9%A9%BE%E6%8A%A4%E8%88%AAfault-tolerant%E4%B8%8E%E4%BF%9D%E8%AF%81exactly-once%E8%AF%AD%E4%B9%89))

- fault tolerant就是从持久化存储中读取上次记录的这些元信息，并且恢复到程序中

- Flink引入了一个概念，叫做Barrier。Barrier是一种标记，它被source产生并且插入到流数据中，被发送到下游节点。当下游节点处理到该barrier标志时，这就意味着在该barrier插入到流数据时，已经进入系统的数据在当前节点已经被处理完毕

- 每当一个barrier流过一个算子节点时，就说明了在该算子上，可以触发一次检查点，用以保存当前节点的状态和已经处理过的数据，这就是一份快照

- 与此同时，该算子会向下游发送该barrier。因为数据在算子之间是按顺序发送的，所以当下游节点收到该barrier时，也就意味着同样的一批数据在下游节点上也处理完毕，可以进行一次checkpoint，保存基于该节点的一份快照，快照完成后，会通知JobMananger自己完成了这个快照

- 如果有不止一个下游节点，就向每个下游发送barrier

- 如果有不止一个上游节点，那么就要等到所有上游节点的同一批次的barrier到达之后，才能触发checkpoint。因为每个节点运算速度不同，所以有的上游节点可能已经在发下个barrier周期的数据了，有的上游节点还没发送本次的barrier，这时候，当前算子就要缓存一下提前到来的数据，等比较慢的上游节点发送barrier之后，才能处理下一批数据

- 当整个程序的最后一个算子sink都收到了这个barrier，也就意味着这个barrier和上个barrier之间所夹杂的这批元素已经全部落袋为安。这时，最后一个算子通知JobManager整个流程已经完成，而JobManager随后发出通知，要求所有算子删除本次快照内容，以完成清理

--4.4 流处理引擎提供的三种数据处理语义(该部分主要参考：[谈谈流计算中的『Exactly Once』特性](https://zhuanlan.zhihu.com/p/69958793))

- 流处理引擎提供的三种数据处理语义
   - 最多一次（At-most-once）：本质上是一『尽力而为』的方法。保证数据或事件最多由应用程序中的所有算子处理一次。 这意味着如果数据在被流应用程序完全处理之前发生丢失，则不会进行其他重试或者重新发送
   - 至少一次（At-least-once）：应用程序中的所有算子都保证数据或事件至少被处理一次。这通常意味着如果事件在流应用程序完全处理之前丢失，则将从源头重放或重新传输事件。然而，由于事件是可以被重传的，因此一个事件有时会被处理多次，这就是所谓的至少一次
   - 精确一次（Exactly-once）：即使是在各种故障的情况下，流应用程序中的所有算子都保证事件只会被『精确一次』的处理

- 对Exactly-once的理解
   - 事件的处理可以发生多次，但是该处理的效果只在持久后端状态存储中反映一次，流处理引擎管理的算子状态的不同更新只反映一次

--4.5 Flink通过两阶段提交协议提供端到端的Exactly-Once保证(该部分主要参考：[深入理解Flink ---- End-to-End Exactly-Once语义](https://www.cnblogs.com/tuowang/p/9025266.html))

- Exactly-Once语义是针对Flink系统内部而言的，结合Kafka如何构建端到端的Exactly-Once处理

- 两阶段提交协议
   - 第一阶段Phase 1，Pre-commit：Flink的JobManager向source注入checkpoint barrier以开启这次snapshot，barrier从source流向sink，每个进行snapshot的算子成功snapshot后,都会向JobManager发送ACK，当sink完成snapshot后, 向JobManager发送ACK的同时向kafka进行pre-commit
   - 第二阶段Phase 2，Commit：当JobManager接收到所有算子的ACK后,就会通知所有的算子这次checkpoint已经完成，Sink接收到这个通知后, 就向kafka进行commit,正式把数据写入到kafka

- 不同阶段错误的恢复
   - 在pre-commit前fail over, 系统恢复到最近的checkponit
   - 在pre-commit后,commit前fail over,系统恢复到刚完成pre-commit时的状态

- Flink的two phase commit实现：抽象类TwoPhaseCommitSinkFunction
   - beginTransaction()：开启事务.创建一个临时文件.后续把原要写入到外部系统的数据写入到这个临时文件
   - preCommit()：flush并close这个文件,之后便不再往其中写数据.同时开启一个新的事务供下个checkponit使用
   - commit()：把pre-committed的临时文件移动到指定目录
   - abort()：删除掉pre-committed的临时文件


**5 Flink流处理的时间窗口**

--5.1 Flink的时间模型

- EventTime是数据被生产出来的时间，可以是比如传感器发出信号的时间等（此时数据还没有被传输给flink）

- IngestionTime是数据进入flink的时间，也就是从Source进入flink流的时间（此时数据刚刚被传给flink）

- ProcessingTime是针对当前算子的系统时间，是指该数据已经进入某个operator时，operator所在系统的当前时间

--5.2 乱序问题

- 乱序问题一般是和EventTime关联的，对于一个流式处理系统的process time来说，是不存在乱序问题的。所以下面介绍的watermark/allowedLateness也只是在EventTime作为主时间才生效

- Flink通过watermark+window+trigger解决乱序问题
   - window解决的是where，也就是将无界数据划分成有界数据(window提供了allowedLateness方法，使得更大限度的允许乱序)
   - trigger用来设计窗口数据触发条件
   - watermark用来标记窗口的完整性

--5.3 watermark+window+trigger解决乱序问题

- watermark(水位线)
   - watermark是流式系统中主要用于解决流式系统中数据乱序问题的机制，方法是用于标记当前处理到什么水位的数据了，这意味着再早于这个水位的数据过来会被直接丢弃。这使得引擎可以自动跟踪数据中的当前事件时间，并尝试相应地清除旧状态
   - watermark和数据本身一样作为正常的消息在流中流动

- trigger
   - trigger指明在哪些条件下触发window计算，基于处理数据时的时间以及事件的特定属性。一般trigger的实现是当watermark处于某种时间条件下或者窗口数据达到一定条件，窗口的数据开始计算
   - 每次trigger对新增的数据相关的window进行重新计算，输出有complete, append,update三种输出模式
      - Complete mode(全量模式)：Result Table 全量输出，也就是重新计算过的window结果都输出。意味着这种模式下，每次读了新增的input数据，output的时候会把内存中resulttable中所有window的结果都输出一遍
      - Append mode (default)(增量模式)：只有 Result Table 中新增的行才会被输出，所谓新增是指自上一次 trigger 的时候。因为只是输出新增的行，所以如果老数据有改动就不适合使用这种模式。 更新的window并不输出，否则外存里的key就重了
      - Update mode(更新模式)：只要更新的 Row 都会被输出，相当于 Append mode 的加强版。而且是对外存中的相同key进行update，而不是append，需要外存是能kv操作的！只会输出新增和更新过的window的结果

- window的allowedLateness
   - allowedLateness就是针对event time而言，对于watermark超过end-of-window之后，还允许有一段时间（也是以event time来衡量）来等待之前的数据到达，以便再次处理这些数据
   - watermark是全局性的参数，用于管理消息的乱序，watermark超过window的endtime之后，就会触发窗口计算。一般情况下，触发窗口计算之后，窗口就销毁掉了，后面再来的数据也不会再计算，对于trigger是默认的EventTimeTrigger的情况下，allowedLateness会再次触发窗口的计算，而之前触发的数据，会buffer起来，直到watermark超过end-of-window + allowedLateness的时间，窗口的数据及元数据信息才会被删除
   - 比如window的endtime是5000，allowedLateness=0，那么如果watermark 5000到来之后，这个window就应该被清除。但是如果allowedLateness = 1000，则需要等water 6000(endtime + allowedLateness)到来之后，这个window才会被清掉

--5.4 watermark的生成和传递

- watermark的生成
   - Flink通过水位线分配器（TimestampsAndPeriodicWatermarksOperator和TimestampsAndPunctuatedWatermarksOperator这两个算子）向事件流中注入水位线。元素在streaming dataflow引擎中流动到WindowOperator时，会被分为两拨，分别是普通事件和水位线

- watermark的传递
   - 算子接受到的水印是来自其数据上游所有watermark的最小值
   - watermark以广播的形式在算子之间传播，当一个算子收到watermark时都要
      - 更新算子时间
      - 遍历计时器队列触发回调
      - 将watermark发送到下游

--5.5 备注：该部分主要参考[[源码分析] 从源码入手看 Flink Watermark 之传播过程](https://www.cnblogs.com/rossiXYZ/p/12345969.html)

**6 Flink处理反压问题**

--6.1 Storm、Spark  Streaming、Flink 提供的反压机制比较

- 反压（Backpressure）:消费者需要多少，生产者就生产多少

- Storm
   - 自动反压机制(Automatic Back Pressure)通过监控Bolt中的接收队列的负载情况，如果超过高水位就会将反压信息写入zk，zk上的watch就会通知该拓扑的所有worker进入反压，最后Spout停止发送数据，直到接收队列的负载降到低水位以下
   - 存在的问题就是， 当下游出现阻塞时， 上游停止发送， 下游消除阻塞后，上游又开闸放水，过了一会儿，下游又阻塞，上游又限流， 如此反复， 整个数据流一直处在一个颠簸状态
   - Jstorm的改进方案是逐级降速与放水来进行反压；另外，Jstorm没有引入zk，而是通过TopologyMaster来协调拓扑进行反压

- Spark  Streaming
   - Spark Streaming程序中当计算过程中出现batch processing time > batch interval的情况时，(其中batch processing time为实际计算一个批次花费时间，batch interval为Streaming应用设置的批处理间隔),意味着处理数据的速度小于接收数据的速度，如果这种情况持续过长的时间，会造成数据在内存中堆积，导致Receiver所在Executor内存溢出等问题
   - Spark Streaming Backpressure: 根据JobScheduler反馈作业的执行信息来动态调整Receiver数据接收率。通过属性”spark.streaming.backpressure.enabled”来控制是否启用backpressure机制，默认值false，即不启用

- Flink
   - 固定大小缓冲池就像阻塞队列一样，保证了Flink有一套健壮的反压机制，使得 Task 生产数据的速度不会快于消费的速度。该方案可以从两个 Task 之间的数据传输自然地扩展到更复杂的 pipeline 中，保证反压机制可以扩散到整个 pipeline
   - 由Flink的网络传输中的内存管理来分析它的反压机制
      - 每个 Task 都包括了输入IG和输入RS，输入和输出的数据存在 Buffer 中（都是字节数据），网络上传输的数据会写到 Task 的 InputGate（IG）中，经过Task的处理后，再由Task写到 ResultPartition（RS）中
      - NetworkEnvironment 和 NetworkBufferPool 是 Task 之间共享的，每个 TM 只会实例化一个。TaskManager（TM）在启动时，会先初始化NetworkEnvironment对象，TM 中所有与网络相关的东西都由该类来管理（如 Netty 连接），其中就包括NetworkBufferPool
      - Task 线程启动时，会向 NetworkEnvironment 注册，NetworkEnvironment 会为 Task 的 InputGate（IG）和 ResultPartition（RP） 分别创建一个 LocalBufferPool（缓冲池）并设置可申请的 MemorySegment（内存块）数量。每当创建或销毁缓冲池时，NetworkBufferPool 会计算剩余空闲的内存块数量，并平均分配给已创建的缓冲池。注意，这个过程只是指定了缓冲池所能使用的内存块数量，并没有真正分配内存块，只有当需要时才分配。在 Task 线程执行过程中，当 Netty 接收端收到数据时，为了将 Netty 中的数据拷贝到 Task 中，InputChannel（实际是 RemoteInputChannel）会向其对应的缓冲池申请内存块（上图中的①）。如果缓冲池中也没有可用的内存块且已申请的数量还没到池子上限，则会向 NetworkBufferPool 申请内存块（上图中的②）并交给 InputChannel 填上数据（上图中的③和④）。如果缓冲池已申请的数量达到上限了呢？或者 NetworkBufferPool 也没有可用内存块了呢？这时候，Task 的 Netty Channel 会暂停读取，上游的发送端会立即响应停止发送，拓扑会进入反压状态。当 Task 线程写数据到 ResultPartition 时，也会向缓冲池请求内存块，如果没有可用内存块时，会阻塞在请求内存块的地方，达到暂停写入的目的。当一个内存块被消费完成之后（在输入端是指内存块中的字节被反序列化成对象了，在输出端是指内存块中的字节写入到 Netty Channel 了），会调用 Buffer.recycle() 方法，会将内存块还给 LocalBufferPool （上图中的⑤）。如果LocalBufferPool中当前申请的数量超过了池子容量（由于上文提到的动态容量，由于新注册的 Task 导致该池子容量变小），则LocalBufferPool会将该内存块回收给 NetworkBufferPool（上图中的⑥）。如果没超过池子容量，则会继续留在池子中，减少反复申请的开销
   - 本地传输：如果 Task 1 和 Task 2 运行在同一个 worker 节点（TaskManager），该 buffer 可以直接交给下一个 Task。一旦 Task 2 消费了该 buffer，则该 buffer 会被缓冲池1回收。如果 Task 2 的速度比 1 慢，那么 buffer 回收的速度就会赶不上 Task 1 取 buffer 的速度，导致缓冲池1无可用的 buffer，Task 1 等待在可用的 buffer 上。最终形成 Task 1 的降速
   - 远程传输：如果 Task 1 和 Task 2 运行在不同的 worker 节点上，那么 buffer 会在发送到网络（TCP Channel）后被回收。在接收端，会从 LocalBufferPool 中申请 buffer，然后拷贝网络中的数据到 buffer 中。如果没有可用的 buffer，会停止从 TCP 连接中读取数据。在输出端，通过 Netty 的水位值机制来保证不往网络中写入太多数据（后面会说）。如果网络中的数据（Netty输出缓冲中的字节数）超过了高水位值，我们会等到其降到低水位值以下才继续写入数据。这保证了网络中不会有太多的数据。如果接收端停止消费网络中的数据（由于接收端缓冲池没有可用 buffer），网络中的缓冲数据就会堆积，那么发送端也会暂停发送。另外，这会使得发送端的缓冲池得不到回收，writer 阻塞在向 LocalBufferPool 请求 buffer，阻塞了 writer 往 ResultSubPartition 写数据

   - Netty 水位值机制
      - 当输出缓冲中的字节数超过了高水位值, 则 Channel.isWritable() 会返回false。当输出缓存中的字节数又掉到了低水位值以下, 则 Channel.isWritable() 会重新返回true

--6.2 排查反压瓶颈，处理反压问题

- 反压的影响
   - 反压会影响到两项指标: checkpoint 时长和 state 大小
   - checkpoint barrier 是不会越过普通数据的，数据处理被阻塞也会导致 checkpoint barrier 流经整个数据管道的时长变长，checkpoint 时间变长有可能导致 checkpoint 超时失败
   - 对于有两个以上输入管道的 Operator，checkpoint barrier 需要对齐（Alignment），接受到较快的输入管道的 barrier 后，它后面数据会被缓存起来但不处理，直到较慢的输入管道的 barrier 也到达，这些被缓存的数据会被放到state 里面， state 大小同样可能拖慢 checkpoint 甚至导致 OOM （使用 Heap-based StateBackend）或者物理内存使用超出容器资源（使用 RocksDBStateBackend）的稳定性问题

- 处理反压问题步骤
   - 1.定位反压节点；2.分析具体原因及处理
      - 定位反压可以从 Web UI 的反压监控面板和 Task Metric 两者入手，前者方便简单分析，后者适合深入挖掘。定位到反压节点后我们可以通过数据分布、CPU Profile 和 GC 指标日志等手段来进一步分析反压背后的具体原因并进行针对性的优化
   - 定位到造成反压的节点，这主要有两种办法: 1.通过 Flink Web UI 自带的反压监控面板；2.通过 Flink Task Metrics
      - Flink Web UI 的反压监控提供了 SubTask 级别的反压监控，原理是通过周期性对 Task 线程的栈信息采样，计算线程请求buffer的阻塞率 = 线程被阻塞在请求 Buffer（意味着被下游队列阻塞）的频率来判断该节点是否处于反压状态。默认配置下，这个频率在 0.1 以下则为 OK，0.1 至 0.5 为 LOW，而超过 0.5 则为 HIGH
         - 处于反压状态，那么有两种可能性：该节点的发送速率跟不上它的产生数据速率，该节点则为反压的根源节点；下游的节点接受速率较慢，通过反压机制限制了该节点的发送速率，需要排查下游节点
      - Task Metrics
         - 以下是几个 Metrics:
         
         | Metris | 描述 |
         | ---- | --- |
         | outPoolUsage|发送端 Buffer 的使用率|
         | inPoolUsage|接收端 Buffer 的使用率 |
         | floatingBuffersUsage（1.9 以上）|接收端 Floating Buffer 的使用率 |
         | exclusiveBuffersUsage （1.9 以上）|接收端 Exclusive Buffer 的使用率 |
    
         - outPoolUsage 和 inPoolUsage 同为低或同为高分别表明当前 Subtask 正常或处于被下游反压，这应该没有太多疑问。而比较有趣的是当 outPoolUsage 和 inPoolUsage 表现不同时，这可能是出于反压传导的中间状态或者表明该 Subtask 就是反压的根源。如果一个 Subtask 的 outPoolUsage 是高，通常是被下游 Task 所影响，所以可以排查它本身是反压根源的可能性。如果一个 Subtask 的 outPoolUsage 是低，但其 inPoolUsage 是高，则表明它有可能是反压的根源。因为通常反压会传导至其上游，导致上游某些 Subtask 的 outPoolUsage 为高
   - 分析具体原因及处理
      - 数据分布造成：很多情况下的反压是由于数据倾斜造成的，这点我们可以通过 Web UI 各个 SubTask 的 Records Sent 和 Record Received 来确认，另外 Checkpoint detail 里不同 SubTask 的 State size 也是一个分析数据倾斜的有用指标
      - CPU性能：最常见的问题可能是用户代码的执行效率问题（频繁被阻塞或者性能问题）。最有用的办法就是对 TaskManager 进行 CPU profile，从中我们可以分析到 Task Thread 是否跑满一个 CPU 核：如果是的话要分析 CPU 主要花费在哪些函数里面，比如我们生产环境中就偶尔遇到卡在 Regex 的用户函数（ReDoS）；如果不是的话要看 Task Thread 阻塞在哪里，可能是用户函数本身有些同步的调用，可能是 checkpoint 或者 GC 等系统活动导致的暂时系统暂停。当然，性能分析的结果也可能是正常的，只是作业申请的资源不足而导致了反压，这就通常要求拓展并行度
      - GC：TaskManager 的内存以及 GC 问题也可能会导致反压，包括 TaskManager JVM 各区内存不合理导致的频繁 Full GC 甚至失联。推荐可以通过给 TaskManager 启用 G1 垃圾回收器来优化 GC，并加上 -XX:+PrintGCDetails 来打印 GC 日志的方式来观察 GC 的问题

--6.3 处理 Flink 作业中的数据倾斜问题

- 数据倾斜就是我们在计算数据的时候，数据的分散度不够，导致大量的数据集中到了一台或者几台机器上计算，这些数据的计算速度远远低于平均计算速度，导致整个计算过程过慢

- 数据重分布：默认情况下，数据是自动分配到多个实例上的。有的时候，我们需要手动对数据在多个实例上进行分配，例如，我们知道某个实例上的数据过多，其他实例上的数据稀疏，产生了数据倾斜，这时我们需要将数据均匀分布到各个实例上，以避免部分实例负载过重。数据倾斜问题会导致整个作业的计算时间过长或者内存不足等问题

- 下文涉及到的各个数据重分布算子的输入是DataStream，输出也是DataStream。keyBy也有对数据进行分组和数据重分布的功能，但keyBy输出的是KeyedStream
   - shuffle基于正态分布，将数据随机分配到下游各算子实例上
~~~
   dataStream.shuffle()
~~~
   - 
   -
   

--6.2 

--6.3 

--6.4 